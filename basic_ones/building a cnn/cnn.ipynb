{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's build an CNN with pytorch \n",
    "I will build an cnn and apply data augmentation  and batch normalization \n",
    "## What's cnn?\n",
    "- CCNs are probably the most popular of all neural networ architecures. \n",
    "\n",
    "- This is mainly because, although they work in many domains, they are particularly good at dealing with images, and advances in technology have allowed the collection of large amounts of images to be possible in order to tackle a great variety of today's challenges.\n",
    "\n",
    "- From image classification to object detection, CNNs are being used to diagnose cancer patients and detect fraud in systems, as well as to construct well thought-out self- driving vehicles that will revolutionize the future.\n",
    "## Building Blocks of CNNs\n",
    "A deep convolutional network is one that takes an image as an input, passes it through a series of convolutional layers with filters, pooling layers, and fully connected layers, to finally apply a softmax activation function that classifies the image into a class label. The classification, as with ANNs, is performed by calculating the probability of the image belonging to each of the class labels, giving each class label a value between zero and one. The class label with the higher probability is the one\n",
    "selected as the final prediction for that image.\n",
    "### Convolutional layers \n",
    "This is the first step to extract features from an image. The objective is to maintain the\n",
    "relation between nearby pixels by learning the features over small sections of the image A mathematical operation occurs in this layer, where two inputs are given (the image\n",
    "and the filter) and an output is obtained. As explained before, the operation consists\n",
    "of convolving the filter and a section of the image of the same size of the filter. This\n",
    "operation is repeated for all subsections of the image.\n",
    "### Padding\n",
    "The padding feature, as the name indicates, pads the image with zeros. This means that\n",
    "it adds additional pixels to each side of the image, which are filled with zeros.\n",
    "### Strdie\n",
    "This parameter refers to the number of pixels that the filter will shift over the input\n",
    "matrix, both horizontally and vertically. As we have seen so far, the filter is passed\n",
    "through the top-left corner of the image, then it shifts over to the right by one pixel,\n",
    "and so on until it has gone through all sections of the image vertically and horizontally.\n",
    "This example is one of a convolutional layer, with stride equal to one, which is the\n",
    "default configuration for this parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation \n",
    "In simple words, it is a measure to\n",
    "increase the number of training examples by slightly modifying the existing examples.\n",
    "For example, you could duplicate the instances currently available and add some noise\n",
    "to those duplicates to make sure they are not exactly the same.\n",
    "In computer vision problems, this means incrementing the number of images in the\n",
    "training dataset by altering the existing images, which can be done by slightly altering\n",
    "the current images to create duplicated versions that are slightly different\n",
    "These minor adjustments to the images can be in the form of slight rotations, changes\n",
    "in the position of the object in the frame, horizontal or vertical flips, different color\n",
    "schemes, and distortions, among others. This technique works considering that CNNs\n",
    "will consider each of these images a different image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.5), \n",
    "        transforms.RandomGrayscale(0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the pixels into tensor datatype and normalizing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_data = datasets.CIFAR10('data3', train=True, download=True, transform=transform[\"train\"])\n",
    "test_data = datasets.CIFAR10('data3', train=False, download=True, transform=transform[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 100 \n",
    "## downloading the data set from datasets module \n",
    "train_data = datasets.CIFAR10('data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10('data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dev_size = 0.2 #Using a validation size of 20%, define the training and validation sampler that will be used to divide the dataset into those two sets.\n",
    "idx = list(range(len(train_data)))\n",
    "np.random.shuffle(idx)\n",
    "split_size = int(np.floor(dev_size * len(train_data)))\n",
    "train_idx, dev_idx = idx[split_size:], idx[:split_size]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "dev_sampler = SubsetRandomSampler(dev_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The SubsetRandomSampler() function from pytorch is used to divide the original training set into training and validations by randomly sampling indexes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dev_size = 0.2\n",
    "idx = list(range(len(train_data)))\n",
    "np.random.shuffle(idx)\n",
    "split_size = int(np.floor(dev_size * len(train_data)))\n",
    "train_idx, dev_idx = idx[split_size:], idx[:split_size]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "dev_sampler = SubsetRandomSampler(dev_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The DataLoader() functions are the ones in charge of loading the images by batches.The resulting variables(train_loader,dev_loader,and test_loader) of this function will contain the values for the features and the target separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "dev_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=dev_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the architecture of your network. Use the following information to do so:\n",
    "• Conv1: A convolutional layer that takes as input the colored image and passes it\n",
    "through 10 filters of size 3. Both the padding and the stride should be set to 1.\n",
    "\n",
    "• Conv2: A convolutional layer that passes the input data through 20 filters of size 3.\n",
    "Both the padding and the stride should be set to 1.\n",
    "\n",
    "• Conv3: A convolutional layer that passes the input data through 40 filters of size\n",
    "three. Both the padding and the stride should be set to 1.\n",
    "\n",
    "• Use the ReLU activation function after each convolutional layer.\n",
    "\n",
    "• A pooling layer after each convolutional layer, with a filter size and stride of 2.\n",
    "\n",
    "• A dropout term set to 20% after flattening the image.\n",
    "\n",
    "• Linear1: A fully-connected layer that receives as input the flattened matrix from\n",
    "the previous layer and generates an output of 100 units. Use the ReLU activation\n",
    "function for this layer. A dropout term here is set to 20%.\n",
    "\n",
    "• Linear2: A fully-connected layer that generates 10 outputs, one for each class label.\n",
    "Use the log_softmax activation function for the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 3, 1, 1)\n",
    "        self.norm1 = nn.BatchNorm2d(10)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3, 1, 1)\n",
    "        self.norm2 = nn.BatchNorm2d(20)\n",
    "        self.conv3 = nn.Conv2d(20, 40, 3, 1, 1)\n",
    "        self.norm3 = nn.BatchNorm2d(40)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.linear1 = nn.Linear(40 * 4 * 4, 100)\n",
    "        self.norm4 = nn.BatchNorm1d(100)\n",
    "        self.linear2 = nn.Linear(100, 10)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.norm1(F.relu(self.conv1(x))))\n",
    "        x = self.pool(self.norm2(F.relu(self.conv2(x))))\n",
    "        x = self.pool(self.norm3(F.relu(self.conv3(x))))\n",
    "\n",
    "        x = x.view(-1, 40 * 4 * 4)\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm4(F.relu(self.linear1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.log_softmax(self.linear2(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train your network and be sure to save the values for the loss and accuracy of both the training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_losses, dev_losses, train_acc, dev_acc= [], [], [], []\n",
    "x_axis = []\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    losses = 0\n",
    "    acc = 0\n",
    "    iterations = 0\n",
    "    \n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        iterations += 1\n",
    "\n",
    "        pred = model(data)\n",
    "        loss = loss_function(pred, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses += loss.item()\n",
    "        p = torch.exp(pred)\n",
    "        top_p, top_class = p.topk(1, dim=1)\n",
    "        acc += accuracy_score(target, top_class)\n",
    "        \n",
    "    dev_losss = 0\n",
    "    dev_accs = 0\n",
    "    iter_2 = 0\n",
    "        \n",
    "    if e%5 == 0 or e == 1:\n",
    "        x_axis.append(e)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            for data_dev, target_dev in dev_loader:\n",
    "                iter_2 += 1\n",
    "                \n",
    "                dev_pred = model(data_dev)\n",
    "                dev_loss = loss_function(dev_pred, target_dev)\n",
    "                dev_losss += dev_loss.item()\n",
    "\n",
    "                dev_p = torch.exp(dev_pred)\n",
    "                top_p, dev_top_class = dev_p.topk(1, dim=1)\n",
    "                dev_accs += accuracy_score(target_dev, dev_top_class)\n",
    "        \n",
    "        train_losses.append(losses/iterations)\n",
    "        dev_losses.append(dev_losss/iter_2)\n",
    "        train_acc.append(acc/iterations)\n",
    "        dev_acc.append(dev_accs/iter_2)\n",
    "        \n",
    "        print(\"Epoch: {}/{}.. \".format(e, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(losses/iterations),\n",
    "              \"Validation Loss: {:.3f}.. \".format(dev_losss/iter_2),\n",
    "              \"Training Accuracy: {:.3f}.. \".format(acc/iterations),\n",
    "              \"Validation Accuracy: {:.3f}\".format(dev_accs/iter_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot the loss and accuracy of both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x_axis,train_losses, label='Training loss')\n",
    "plt.plot(x_axis, dev_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x_axis, train_acc, label=\"Training accuracy\")\n",
    "plt.plot(x_axis, dev_acc, label=\"Validation accuracy\")\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "iter_3 = 0\n",
    "acc_test = 0\n",
    "for data_test, target_test in test_loader:\n",
    "    iter_3 += 1\n",
    "    test_pred = model(data_test)\n",
    "    test_pred = torch.exp(test_pred)\n",
    "    top_p, top_class_test = test_pred.topk(1, dim=1)\n",
    "    acc_test += accuracy_score(target_test, top_class_test)\n",
    "print(acc_test/iter_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('python10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "23be68f5752c5ca0bc45d553b716a509df366b3fb08f23244f11989bd6453b64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
